# 典型回答
有的时候，当我们对数据库做了分库分表后，因为最初的预估数据不够准确，导致后续数据增长很快，表不够了，那么遇到这种情况该怎么办呢？

首先，我们应该尽量避免这种情况的发生，在第一次决定分表的时候，就尽可能根据当前的业务增长量预估一下未来可能需要存储的数据量，并且最好一定的buffer，让这个分表尽可能够，避免出现不够的情况。

比如我们线上分表基本都是256、512、1024这样分的。

其次，如果真的后面就不够了，其实也没啥特别好的办法，要么就通用其他的手段来减少数据量，比如我们之前提到过的数据归档等。

[✅如果单表数据量大，只能考虑分库分表吗？](https://www.yuque.com/hollis666/fo22bm/dk6tpttlf2aex9ap?view=doc_embed)

那还有，就只剩一条路了，那就是二次分表，即原来的128张不够，那么就需要重新分成256张表。这个过程和第一次从单表分成128张表过程差不多。

涉及到分表算法的更新，数据的迁移等。其中最关键的就是如何无损、无缝的做数据迁移了，这个我后面会再加一篇单独写如何做数据迁移。（占坑。）

另外，还有一个值得考虑的，就是如果最开始用的是一致性hash的算法进行分表路由，那么在做二次分表的时候，数据迁移的成本就会低很多，因为影响的节点可能没那么多。

[✅什么是一致性哈希？](https://www.yuque.com/hollis666/fo22bm/hgx0twgg4t7nqg6v?view=doc_embed)

所以，总结一下，就是要么提前多分点、要么就是先办法减少数据量，如做数据归档，要么就是重新分，然后做数据迁移。如果提前考虑过的话，用了一致性哈希的话会影响更小一点。除了这些，也没啥更好的办法了。
