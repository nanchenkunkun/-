# 典型回答

[✅如何基于本地消息表实现分布式事务？](https://www.yuque.com/hollis666/fo22bm/xm675quxo1bc5qm8?view=doc_embed)

本地消息表的分布式事务方案是依赖本地消息表，然后通过定时任务扫表的方式来实现的最终一致性。那么这个方案，整体上来看，在以下几个方面是有问题的：

**1、消息堆积扫表慢**<br />**2、集中式扫表会影响正常业务**<br />**3、定时扫表存在延迟问题**

那么，这几个问题，该如何解决呢？

### 消息堆积，扫表慢

随着本地消息表中的数据量越来越大，通过定时任务扫表的方式会越来越慢，那么想要解决这个问题，首先可以考虑加索引。

我们可以在state字段上增加一个索引，虽然这个字段的区分度不高，但是一般来说，这张表中，SUCCESS的数据量占90%，而INIT的数据量只占10%，而我们扫表的时候只关心INIT即可，所以增加索引后，扫表的效率是可以大大提升的。

[✅区分度不高的字段建索引一定没用吗？](https://www.yuque.com/hollis666/fo22bm/nr83t255g22gu3v7?view=doc_embed)

其次，可以考虑多线程并发扫表，这里可以考虑采用线程池，在任务中开多个线程并发的从数据库中扫描数据进行处理。

但是这样做，会带来一个问题，那就是多个线程之间如何做好隔离，如何确保不会出现并发导致同一条记录被多个线程执行多次呢？

首先最基本的保障，扫表之后的处理逻辑要做好幂等控制，一旦出现了重复的情况，下游也能因为做了幂等而不会重复处理。

除此以外，在扫表的时候，可以通过分段的思想进行数据隔离。举个例子：

```java
Long minId = messageService.getMinInitId();


for(int i=1;i<= threadPool.size();i++){
    Long maxId = minId + segmentSize()*i;

    List<Message> messages = messageService.scanInitMessages(minId,maxId);

    proccee(messages);
    minId = maxId + 1;
}
```

像上面的例子中，假设有10个线程，那么第一个线程就扫描ID处于0-1000的数据，第二个线程扫描1001-2000的数据，第三个线程扫描2001-3000的数据。这样以此类推，线程之间通过分段的方式就做好了隔离，可以避免同一个数据被多个线程扫描到。

这个做法，有个小问题，那就是INIT的数据的ID可能不是连续的，那么就需要考虑其他的分段方式，比如在时间表中增加一个业务ID，然后根据这个biz_id做分片也可以。

比如：
```java

for(int i=1;i<= threadPool.size();i++){
    List<Message> messages = messageService.scanInitMessages(i);
    proccee(messages);
}
```

这样在SQL中：

```java
SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "${frontNumber}%"
```
那么，不同的线程执行的SQL就不一样了分别是：

```java
SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "1%"

SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "2%"

SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "3%"

SELECT * FROM RETRY_MESSAGE WHERE 
STATE = "INIT"
AND BIZ_ID LIKE "4%"
```

这样也是可以做分段的。

### **集中式扫表会影响正常业务**

如果业务量比较大的话，集中式的扫描数据库势必给数据库带来一定的压力，那么就会影响到正常的业务。

> 因为数据量大的话会一直扫表做查询，数据量大的时候查询就会很慢，那么数据库连接数就会被占满。导致应用的正常请求拿不到连接.


那么想要解决这个问题，首先可以考虑，不扫主库，而是扫描备库。之所以能这么做，是因为这个业务场景一般都是可以接受一定的数据延迟的，那么备库带来延迟就可以忽略，但是备库是没有业务操作的，所以对备库的扫描是不会对业务造成影响的。

当然，这里还要考虑一个问题，那就是备库扫描数据之后的执行，执行完该如何同步到主库，这里可以直接修改主库，主备库数据ID一致的，直接去修改主库的就行了。不建议直接在备库上修改。

但是不管怎么样，备库还是可以分担扫表的这个大量高峰请求的。

除了扫备库，还有一个方案，那就是做分库了。把原来集中在同一个数据库的数据分散到不同的数据库中，这样用集群代替单库来整体对外提供服务，可以大大的提升吞吐量。

因为多个数据库的话，每个库提供的连接数就会多，并且多个实例的话，CPU、IO、LOAD这些指标也可以互相分担。


### **定时扫表存在延迟问题**

定时任务都是集中式的定时执行的，那么就会存在延迟的问题。随着数据库越来越大，延时会越来越长。

想要降低延迟，那就要抛弃定时任务的方案，可以考虑延迟消息，基于延迟消息来做定时执行。

用了延迟消息之后，还可以缓解数据库的压力。也能比定时扫表的性能要好，实时性也更高。

[✅订单到期关闭如何实现](https://www.yuque.com/hollis666/fo22bm/tg0ehg?view=doc_embed)

当然，引入另外一个中间件也需要考虑成本的。

### 同步转异步

再提一个方案，那就是同步转异步。什么叫同步转异步呢，那就是同步先干一把，失败了的话，再异步执行。如：

```java
private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder()
    .setNameFormat("hollis-pool-%d").build();

private static ExecutorService pool = new ThreadPoolExecutor(5, 200,
    0L, TimeUnit.MILLISECONDS,
    new LinkedBlockingQueue<Runnable>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());

@Transactional(rollbackFor = Exception.class)
public void pay(PayRequest payRequest){

	//在同一个事务中做本地业务操作和记录消息
	payService.doPay(payRequest);
    retryMessageService.init(payRequest);

	//同步执行一次外部调用
    try{
        Result result = outerService.doSth(payRequest);
        if(result.isSuccess()){
            retryMessageService.success(payRequest);
        }
    }catch(Exception e){
        // 捕获异常，失败依赖异步重试
    }
	

}

```

如上，在同步接口中，先尝试着执行一次要可能会失败的任务，如果成功了，那就把事件推进到成功，。如果失败了也无所谓，因为会有异步定时任务捞起来重试。

当然，这个方案在本地事务中做了远程调用，会拖长事务，不太建议，这里建议考虑用SpringEvent的异步事件来实现。

[✅为啥不要在事务中做外部调用？](https://www.yuque.com/hollis666/fo22bm/gxnzfaxighqtaxod?view=doc_embed)

[✅基于Spring Event，实现同步转异步，解决定时任务扫表导致数据库连接池不够的问题](https://www.yuque.com/hollis666/fo22bm/phqa2kizsvmdp7dp?view=doc_embed)
